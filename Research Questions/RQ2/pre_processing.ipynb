{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Brain Tumor Detection Using a Convolutional Neural Network"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**About the Brain MRI Images dataset:**<br>\n",
    "The dataset contains 2 folders: yes and no which contains 253 Brain MRI Images. The folder yes contains 155 Brain MRI Images that are tumorous and the folder no contains 98 Brain MRI Images that are non-tumorous. You can find it [here](https://www.kaggle.com/navoneel/brain-mri-images-for-brain-tumor-detection)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Necessary Modules"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(42)          # Python's random module\n",
    "np.random.seed(42)       # NumPy (used by scikit-learn)\n",
    "tf.random.set_seed(42)   # TensorFlow/Keras\n",
    "os.environ['PYTHONHASHSEED'] = str(42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from medpy.filter.smoothing import anisotropic_diffusion as ani_diff\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from os import listdir\n",
    "from tqdm import tqdm\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Preparation & Preprocessing"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In order to crop the part that contains only the brain of the image, I used a cropping technique to find the extreme top, bottom, left and right points of the brain. You can read more about it here [Finding extreme points in contours with OpenCV](https://www.pyimagesearch.com/2016/04/11/finding-extreme-points-in-contours-with-opencv/)."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def crop_brain_contour(image, plot=False):\n",
    "    \n",
    "    # Convert the image to grayscale, and blur it slightly\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Threshold the image, then perform a series of erosions +\n",
    "    # dilations to remove any small regions of noise\n",
    "    thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
    "    thresh = cv2.erode(thresh, None, iterations=2)\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "\n",
    "    # Find contours in thresholded image, then grab the largest one\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    c = max(cnts, key=cv2.contourArea)\n",
    "    \n",
    "\n",
    "    # Find the extreme points\n",
    "    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
    "    extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
    "    extTop = tuple(c[c[:, :, 1].argmin()][0])\n",
    "    extBot = tuple(c[c[:, :, 1].argmax()][0])\n",
    "    \n",
    "    # crop new image out of the original image using the four extreme points (left, right, top, bottom)\n",
    "    new_image = image[extTop[1]:extBot[1], extLeft[0]:extRight[0]]            \n",
    "\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image)\n",
    "        \n",
    "        plt.tick_params(axis='both', which='both', \n",
    "                        top=False, bottom=False, left=False, right=False,\n",
    "                        labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
    "        \n",
    "        plt.title('Original Image')\n",
    "            \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(new_image)\n",
    "\n",
    "        plt.tick_params(axis='both', which='both', \n",
    "                        top=False, bottom=False, left=False, right=False,\n",
    "                        labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
    "\n",
    "        plt.title('Cropped Image')\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    return new_image"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In order to better understand what it's doing, let's grab an image from the dataset and apply this cropping function to see the result:"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ex_img = cv2.imread('../../yes/Y1.jpg')\n",
    "ex_new_img = crop_brain_contour(ex_img, True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load up the data:"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The following function takes two arguments, the first one is a list of directory paths for the folders 'yes' and 'no' that contain the image data and the second argument is the image size, and for every image in both directories and does the following: \n",
    "1. Read the image.\n",
    "2. Crop the part of the image representing only the brain.\n",
    "3. Resize the image (because the images in the dataset come in different sizes (meaning width, height and # of channels). So, we want all of our images to be (240, 240, 3) to feed it as an input to the neural network.\n",
    "4. Apply normalization because we want pixel values to be scaled to the range 0-1.\n",
    "5. Append the image to <i>X</i> and its label to <i>y</i>.<br>\n",
    "\n",
    "After that, Shuffle <i>X</i> and <i>y</i>, because the data is ordered (meaning the arrays contains the first part belonging to one class and the second part belonging to the other class, and we don't want that).<br>\n",
    "Finally, Return <i>X</i> and <i>y</i>."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def load_data(dir_list,\n",
    "              image_size,\n",
    "              grayscale,\n",
    "              contrast_enhancement,\n",
    "              anisotropic_diffusion,\n",
    "              smoothing,\n",
    "              bilateral_filtering,\n",
    "              clip_limit=3.0,\n",
    "              tile_grid_size=8,\n",
    "              kernel_size=7,\n",
    "              d = 5,\n",
    "              sigma_color = 30,\n",
    "              sigma_space = 30,\n",
    "              aniso_niter = 10,\n",
    "              aniso_kappa = 50,\n",
    "              aniso_gamma = 0.1,\n",
    "              aniso_option = 1):\n",
    "    \"\"\"\n",
    "    Read images, resize and normalize them.\n",
    "    Arguments:\n",
    "        dir_list: list of strings representing file directories.\n",
    "    Returns:\n",
    "        X: A numpy array with shape = (#_examples, image_width, image_height, #_channels)\n",
    "        y: A numpy array with shape = (#_examples, 1)\n",
    "    \"\"\"\n",
    "\n",
    "    # load all images in a directory\n",
    "    X = []\n",
    "    y = []\n",
    "    image_width, image_height = image_size\n",
    "\n",
    "    for directory in dir_list:\n",
    "        for filename in listdir(directory):\n",
    "            # load the image\n",
    "            image = cv2.imread(directory + '\\\\' + filename)\n",
    "\n",
    "            # crop the brain and ignore the unnecessary rest part of the image\n",
    "            image = crop_brain_contour(image, plot=False)\n",
    "\n",
    "            if grayscale:\n",
    "                if len(image.shape) == 3:\n",
    "                    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # resize image\n",
    "            image = cv2.resize(image, dsize=(image_width, image_height), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "            # normalize values\n",
    "            image = image / 255.\n",
    "\n",
    "            if smoothing:\n",
    "                    # Create averaging kernel\n",
    "                    kernel = np.ones((kernel_size, kernel_size), np.float32) / (kernel_size**2)\n",
    "\n",
    "                    # if grayscale or len(image.shape) == 2:\n",
    "                    #     # For grayscale images\n",
    "                    #     image = cv2.filter2D(image, -1, kernel)\n",
    "                    # else:\n",
    "                    # For color images, apply to each channel separately\n",
    "                    for i in range(3):\n",
    "                        image[:,:,i] = cv2.filter2D(image[:,:,i], -1, kernel)\n",
    "\n",
    "            if bilateral_filtering:\n",
    "                # Convert to uint8 for bilateral filter (it requires uint8)\n",
    "                image_uint8 = (image * 255).astype(np.uint8)\n",
    "\n",
    "                # if grayscale or len(image.shape) == 2:\n",
    "                #     # For grayscale images\n",
    "                #     filtered = cv2.bilateralFilter(image_uint8, d, sigma_color, sigma_space)\n",
    "                #     image = filtered.astype(np.float32) / 255.0\n",
    "                # else:\n",
    "                # For color images, apply to each channel separately\n",
    "                filtered = np.zeros_like(image_uint8)\n",
    "                for i in range(3):\n",
    "                    filtered[:,:,i] = cv2.bilateralFilter(image_uint8[:,:,i], d, sigma_color, sigma_space)\n",
    "                image = filtered.astype(np.float32) / 255.0\n",
    "\n",
    "            if anisotropic_diffusion:\n",
    "                # if grayscale or len(image.shape) == 2:\n",
    "                #     # For grayscale images\n",
    "                #     image = anisotropic_diffusion(\n",
    "                #         image,\n",
    "                #         niter=aniso_niter,\n",
    "                #         kappa=aniso_kappa,\n",
    "                #         gamma=aniso_gamma,\n",
    "                #         option=aniso_option\n",
    "                #     )\n",
    "                # else:\n",
    "                # For color images, apply to each channel separately\n",
    "                for i in range(3):\n",
    "                    image[:,:,i] = ani_diff(\n",
    "                        image[:,:,i],\n",
    "                        niter=aniso_niter,\n",
    "                        kappa=aniso_kappa,\n",
    "                        gamma=aniso_gamma,\n",
    "                        option=aniso_option\n",
    "                    )\n",
    "\n",
    "            if contrast_enhancement:\n",
    "                clahe = cv2.createCLAHE(clipLimit=clip_limit,\n",
    "                                        tileGridSize=(tile_grid_size, tile_grid_size))\n",
    "\n",
    "                # if grayscale or len(image.shape) == 2:\n",
    "                #     image_uint8 = (image * 255).astype(np.uint8)\n",
    "                #     image = clahe.apply(image_uint8).astype(np.float32) / 255.0\n",
    "                # else:\n",
    "                image_uint8 = (image * 255).astype(np.uint8)\n",
    "                for i in range(3):\n",
    "                    image[:,:,i] = clahe.apply(image_uint8[:,:,i]).astype(np.float32) / 255.0\n",
    "\n",
    "            # Reshape grayscale images to have a channel dimension\n",
    "            if grayscale or len(image.shape) == 2:\n",
    "                image = np.expand_dims(image, axis=-1)\n",
    "\n",
    "            # convert image to numpy array and append it to X\n",
    "            X.append(image)\n",
    "\n",
    "            # append a value of 1 to the target array if the image\n",
    "            # is in the folder named 'yes', otherwise append 0.\n",
    "            if directory[-3:] == 'yes':\n",
    "                y.append([1])\n",
    "            else:\n",
    "                y.append([0])\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Shuffle the data\n",
    "    X, y = shuffle(X, y)\n",
    "\n",
    "    print(f'Number of examples is: {len(X)}')\n",
    "    print(f'X shape is: {X.shape}')\n",
    "    print(f'y shape is: {y.shape}')\n",
    "\n",
    "    return X, y"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Load up the data that we augmented earlier in the Data Augmentation notebook.<br>\n",
    "**Note:** the augmented data directory contains not only the new generated images but also the original images."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def add_implant_artifact(image, min_radius=50, max_radius=100):\n",
    "    \"\"\"\n",
    "    Add a single simulated brain implant artifact to an MRI scan.\n",
    "\n",
    "    Args:\n",
    "        image: Input MRI image\n",
    "        min_radius: Minimum radius of artifact (default: 15 pixels)\n",
    "        max_radius: Maximum radius of artifact (default: 30 pixels)\n",
    "\n",
    "    Returns:\n",
    "        Image with simulated implant artifact\n",
    "    \"\"\"\n",
    "    img_with_artifact = image.copy()\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) if len(image.shape) == 3 else image\n",
    "    _, brain_mask = cv2.threshold(gray, 20, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    contours, _ = cv2.findContours(brain_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if not contours:\n",
    "        brain_coords = np.column_stack(np.where(brain_mask > 0))\n",
    "        if len(brain_coords) == 0:\n",
    "            return img_with_artifact  # No brain detected, return original image\n",
    "\n",
    "    # Single larger artifact\n",
    "    radius = random.randint(min_radius, max_radius)\n",
    "\n",
    "    if contours:\n",
    "        # Find the largest contour (brain)\n",
    "        brain_contour = max(contours, key=cv2.contourArea)\n",
    "        # Get the moments of the contour\n",
    "        M = cv2.moments(brain_contour)\n",
    "\n",
    "        # Calculate the center of the brain\n",
    "        if M[\"m00\"] != 0:\n",
    "            center_x = int(M[\"m10\"] / M[\"m00\"])\n",
    "            center_y = int(M[\"m01\"] / M[\"m00\"])\n",
    "        else:\n",
    "            center_x, center_y = width // 2, height // 2\n",
    "\n",
    "        # Calculate distance from center to place artifact randomly but within brain\n",
    "        max_distance = min(width, height) // 4\n",
    "        distance = random.randint(0, max_distance)\n",
    "        angle = random.uniform(0, 2 * np.pi)\n",
    "\n",
    "        x = int(center_x + distance * np.cos(angle))\n",
    "        y = int(center_y + distance * np.sin(angle))\n",
    "\n",
    "        # Ensure coordinates are within image boundaries\n",
    "        x = max(radius, min(width - radius, x))\n",
    "        y = max(radius, min(height - radius, y))\n",
    "    else:\n",
    "        # Fallback: place artifact randomly\n",
    "        x = random.randint(radius, width - radius)\n",
    "        y = random.randint(radius, height - radius)\n",
    "\n",
    "    # Create the artifact (black circle)\n",
    "    cv2.circle(img_with_artifact, (x, y), radius, (0, 0, 0), -1)\n",
    "\n",
    "    # Add some blur to make it look more realistic\n",
    "    img_with_artifact = cv2.GaussianBlur(img_with_artifact, (5, 5), 0)\n",
    "\n",
    "    return img_with_artifact\n",
    "\n",
    "def augment_data_implant(input_dir, output_dir, percentage=0.01):\n",
    "    \"\"\"\n",
    "    Process the dataset by adding a single implant artifact to a percentage of images\n",
    "\n",
    "    Args:\n",
    "        input_dir: Input directory containing MRI images\n",
    "        output_dir: Output directory for augmented images\n",
    "        percentage: Percentage of images to augment (default: 0.5)\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Get list of all images in input directory\n",
    "    images = [f for f in os.listdir(input_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "    # Determine which images to augment\n",
    "    num_to_augment = int(len(images) * percentage)\n",
    "    images_to_augment = random.sample(images, num_to_augment)\n",
    "\n",
    "    print(f\"Processing {len(images)} images, augmenting {num_to_augment}\")\n",
    "\n",
    "    for img_name in tqdm(images):\n",
    "        # Read the image\n",
    "        img_path = os.path.join(input_dir, img_name)\n",
    "        image = cv2.imread(img_path)\n",
    "\n",
    "        if image is None:\n",
    "            print(f\"Failed to read image: {img_path}\")\n",
    "            continue\n",
    "\n",
    "        # Convert to RGB (OpenCV reads as BGR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # If this image is selected for augmentation, add artifact\n",
    "        if img_name in images_to_augment:\n",
    "            # Add a single larger artifact\n",
    "            augmented = add_implant_artifact(image)\n",
    "\n",
    "            # Save the augmented image\n",
    "            output_path = os.path.join(output_dir, img_name)\n",
    "            augmented_bgr = cv2.cvtColor(augmented, cv2.COLOR_RGB2BGR)\n",
    "            cv2.imwrite(output_path, augmented_bgr)\n",
    "\n",
    "            # Visualize the original and augmented images\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(5, 5))\n",
    "            axes = axes.flatten()\n",
    "            axes[0].imshow(image, cmap='gray')\n",
    "            axes[0].axis('off')\n",
    "            axes[1].imshow(augmented, cmap='gray')\n",
    "            axes[1].axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            # Copy original image to output directory\n",
    "            output_path = os.path.join(output_dir, img_name)\n",
    "            cv2.imwrite(output_path, image)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "IMG_WIDTH, IMG_HEIGHT = (240, 240)\n",
    "\n",
    "original_augmented_path = '../../augmented data/'\n",
    "\n",
    "# augmented data (yes and no) contains both the original and the new generated examples\n",
    "original_augmented_yes = original_augmented_path + 'yes'\n",
    "original_augmented_no = original_augmented_path + 'no'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As we see, we have 2065 images. Each images has a shape of **(240, 240, 3)=(image_width, image_height, number_of_channels)**"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Plot sample images:"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_example_images(dataset, exp_name):\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(5, 5))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    indices = [0, 1, 2, 3]\n",
    "\n",
    "    for idx, ax in enumerate(axes):\n",
    "        image = dataset[indices[idx]]\n",
    "        if image.shape[-1] == 1:\n",
    "            image = image.squeeze()\n",
    "        ax.imshow(image, cmap='gray')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"images/{exp_name}.png\", dpi=300)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Split the data:\n",
    "Split <i>X</i> and <i>y</i> into training, validation (development) and validation sets."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def split_data(X, y, test_size=0.2):\n",
    "       \n",
    "    \"\"\"\n",
    "    Splits data into training, development and test sets.\n",
    "    Arguments:\n",
    "        X: A numpy array with shape = (#_examples, image_width, image_height, #_channels)\n",
    "        y: A numpy array with shape = (#_examples, 1)\n",
    "    Returns:\n",
    "        X_train: A numpy array with shape = (#_train_examples, image_width, image_height, #_channels)\n",
    "        y_train: A numpy array with shape = (#_train_examples, 1)\n",
    "        X_val: A numpy array with shape = (#_val_examples, image_width, image_height, #_channels)\n",
    "        y_val: A numpy array with shape = (#_val_examples, 1)\n",
    "        X_test: A numpy array with shape = (#_test_examples, image_width, image_height, #_channels)\n",
    "        y_test: A numpy array with shape = (#_test_examples, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=0.5, random_state=42)\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Some helper functions:"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return f\"{h}:{m}:{round(s,1)}\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compute_f1_score(y_true, prob):\n",
    "    # convert the vector of probabilities to a target vector\n",
    "    y_pred = np.where(prob > 0.5, 1, 0)\n",
    "    \n",
    "    score = f1_score(y_true, y_pred)\n",
    "    \n",
    "    return score"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def evaluate(model, X_test, y_test, X_val, y_val):\n",
    "    loss, acc = model.evaluate(x=X_test, y=y_test)\n",
    "    y_val_prob = model.predict(X_val)\n",
    "    f1score_val = compute_f1_score(y_val, y_val_prob)\n",
    "    y_test_prob = model.predict(X_test)\n",
    "    f1score = compute_f1_score(y_test, y_test_prob)\n",
    "\n",
    "    print(f\"Test Loss = {loss}\")\n",
    "    print(f\"Test Accuracy = {acc}\")\n",
    "    print(f\"Val F1 Score: {f1score_val}\")\n",
    "    print(f\"Test F1 Score: {f1score}\")\n",
    "\n",
    "    return {\n",
    "        'test_loss': loss,\n",
    "        'test_accuracy': acc,\n",
    "        'val_f1_score': f1score_val,\n",
    "        'test_f1_score': f1score\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Build the model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def build_model(input_shape):\n",
    "    \"\"\"\n",
    "    Arugments:\n",
    "        input_shape: A tuple representing the shape of the input of the model. shape=(image_width, image_height, #_channels)\n",
    "    Returns:\n",
    "        model: A Model object.\n",
    "    \"\"\"\n",
    "    # Define the input placeholder as a tensor with shape input_shape.\n",
    "    X_input = Input(input_shape) # shape=(?, 240, 240, 3)\n",
    "\n",
    "    # Zero-Padding: pads the border of X_input with zeroes\n",
    "    X = ZeroPadding2D((2, 2))(X_input) # shape=(?, 244, 244, 3)\n",
    "\n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(32, (7, 7), strides = (1, 1), name = 'conv0')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
    "    X = Activation('relu')(X) # shape=(?, 238, 238, 32)\n",
    "\n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((4, 4), name='max_pool0')(X) # shape=(?, 59, 59, 32)\n",
    "\n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((4, 4), name='max_pool1')(X) # shape=(?, 14, 14, 32)\n",
    "\n",
    "    # FLATTEN X\n",
    "    X = Flatten()(X) # shape=(?, 6272)\n",
    "    # FULLYCONNECTED\n",
    "    X = Dense(1, activation='sigmoid', name='fc')(X) # shape=(?, 1)\n",
    "\n",
    "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
    "    model = Model(inputs = X_input, outputs = X, name='BrainDetectionModel')\n",
    "    \n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define the image shape:"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "IMG_SHAPE = (IMG_WIDTH, IMG_HEIGHT, 3)\n",
    "\n",
    "# Create a directory specific to each layer depth\n",
    "model_dir = f\"models/\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "EPOCHS = 10"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Baseline"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "experiment_name = \"baseline\"\n",
    "model = build_model(IMG_SHAPE)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "X, y = load_data(\n",
    "    [original_augmented_yes, original_augmented_no],\n",
    "    (IMG_WIDTH, IMG_HEIGHT),\n",
    "    grayscale=False,\n",
    "    contrast_enhancement=False,\n",
    "    anisotropic_diffusion=False,\n",
    "    smoothing=False,\n",
    "    bilateral_filtering=False\n",
    ")\n",
    "\n",
    "plot_example_images(X, experiment_name)\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_data(X, y, test_size=0.3)\n",
    "\n",
    "# Static file path to ensure only the best model is saved\n",
    "filepath = os.path.join(model_dir, f\"{experiment_name}.keras\")\n",
    "\n",
    "# Save only the best model based on validation accuracy\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=0, save_best_only=True, mode='max')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model without checkpointing\n",
    "model.fit(x=X_train, y=y_train, batch_size=32, epochs=EPOCHS, validation_data=(X_val, y_val), shuffle=True, callbacks=[checkpoint], verbose=1)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = (end_time - start_time)\n",
    "print(f\"{experiment_name} - Elapsed time: {hms_string(execution_time)}\")\n",
    "\n",
    "evaluate(model, X_test, y_test, X_val, y_val)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Grayscale conversion"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "experiment_name = \"grayscale\"\n",
    "model = build_model((IMG_WIDTH, IMG_HEIGHT, 1))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "X, y = load_data(\n",
    "    [original_augmented_yes, original_augmented_no],\n",
    "    (IMG_WIDTH, IMG_HEIGHT),\n",
    "    grayscale=True,\n",
    "    contrast_enhancement=False,\n",
    "    anisotropic_diffusion=False,\n",
    "    smoothing=False,\n",
    "    bilateral_filtering=False\n",
    ")\n",
    "\n",
    "plot_example_images(X, experiment_name)\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_data(X, y, test_size=0.3)\n",
    "\n",
    "# Static file path to ensure only the best model is saved\n",
    "filepath = os.path.join(model_dir, f\"{experiment_name}.keras\")\n",
    "\n",
    "# Save only the best model based on validation accuracy\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=0, save_best_only=True, mode='max')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model without checkpointing\n",
    "model.fit(x=X_train, y=y_train, batch_size=32, epochs=EPOCHS, validation_data=(X_val, y_val), shuffle=True, callbacks=[checkpoint], verbose=1)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = (end_time - start_time)\n",
    "print(f\"{experiment_name} - Elapsed time: {hms_string(execution_time)}\")\n",
    "\n",
    "evaluate(model, X_test, y_test, X_val, y_val)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Contrast Enhancement"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "param_grid = {\n",
    "    'clip_limit': [2.0, 3.0, 4.0],\n",
    "    'tile_grid_size': [4, 8, 12]\n",
    "}\n",
    "\n",
    "best_val_accuracy = 0\n",
    "best_params = None\n",
    "results = []\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    clip_limit = params['clip_limit']\n",
    "    tile_grid_size = params['tile_grid_size']\n",
    "\n",
    "    experiment_name = f\"contrast_enhancement_clip{clip_limit}_grid{tile_grid_size}\"\n",
    "    print(f\"\\nRunning experiment: {experiment_name}\")\n",
    "\n",
    "    model = build_model(IMG_SHAPE)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    X, y = load_data(\n",
    "        [original_augmented_yes, original_augmented_no],\n",
    "        (IMG_WIDTH, IMG_HEIGHT),\n",
    "        grayscale=False,\n",
    "        contrast_enhancement=True,\n",
    "        anisotropic_diffusion=False,\n",
    "        smoothing=False,\n",
    "        bilateral_filtering=False,\n",
    "        clip_limit=clip_limit,\n",
    "        tile_grid_size=tile_grid_size\n",
    "    )\n",
    "\n",
    "    plot_example_images(X, f\"{experiment_name}_{clip_limit}_grid{tile_grid_size}\")\n",
    "\n",
    "    # Split the data\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = split_data(X, y, test_size=0.3)\n",
    "\n",
    "    # Define file path for saving the model\n",
    "    filepath = os.path.join(model_dir, f\"{experiment_name}.keras\")\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=0, save_best_only=True, mode='max')\n",
    "\n",
    "    # Train the model\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        x=X_train, y=y_train,\n",
    "        batch_size=32,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=(X_val, y_val),\n",
    "        shuffle=True,\n",
    "        callbacks=[checkpoint],\n",
    "        verbose=1\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    # Get the best validation accuracy from this run\n",
    "    val_accuracy = max(history.history['val_accuracy'])\n",
    "    print(f\"{experiment_name} - Elapsed time: {hms_string(execution_time)} - Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    test_metrics = evaluate(model, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        'experiment_name': experiment_name,\n",
    "        'clip_limit': clip_limit,\n",
    "        'tile_grid_size': tile_grid_size,\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'test_metrics': test_metrics,\n",
    "        'execution_time': execution_time\n",
    "    })\n",
    "\n",
    "    # Update best parameters if this run is better\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        best_params = params\n",
    "\n",
    "# Prepare data for heatmap\n",
    "clip_limits = param_grid['clip_limit']\n",
    "tile_grid_sizes = param_grid['tile_grid_size']\n",
    "val_accuracies = np.zeros((len(clip_limits), len(tile_grid_sizes)))\n",
    "\n",
    "for result in results:\n",
    "    i = clip_limits.index(result['clip_limit'])\n",
    "    j = tile_grid_sizes.index(result['tile_grid_size'])\n",
    "    val_accuracies[i, j] = result['val_accuracy']\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(val_accuracies, annot=True, fmt=\".4f\", xticklabels=tile_grid_sizes, yticklabels=clip_limits, cmap=\"YlGnBu\")\n",
    "plt.title(\"Validation Accuracy for Contrast Enhancement Parameters\")\n",
    "plt.xlabel(\"Tile Grid Size\")\n",
    "plt.ylabel(\"Clip Limit\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig(f\"images/{experiment_name}_grid-search.png\", dpi=300)\n",
    "\n",
    "# Print grid search results\n",
    "print(\"\\nGrid Search Results:\")\n",
    "for result in results:\n",
    "    print(f\"Experiment: {result['experiment_name']}, Val Accuracy: {result['val_accuracy']:.4f}, \"\n",
    "          f\"Time: {hms_string(result['execution_time'])}\")\n",
    "\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "print(f\"Best Validation Accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "# Print test metrics for the best parameters\n",
    "best_result = next(r for r in results if r['clip_limit'] == best_params['clip_limit'] and r['tile_grid_size'] == best_params['tile_grid_size'])\n",
    "print(f\"\\nTest Metrics for Best Parameters ({best_result['experiment_name']}):\")\n",
    "for metric_name, metric_value in best_result['test_metrics'].items():\n",
    "    print(f\"{metric_name}: {metric_value:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Average Smoothing Filtering"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "param_grid = {\n",
    "    'kernel_size': [5, 7, 9]\n",
    "}\n",
    "\n",
    "best_val_accuracy = 0\n",
    "best_params = None\n",
    "results = []\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    kernel_size = params['kernel_size']\n",
    "\n",
    "    experiment_name = f\"smoothing_kernel{kernel_size}\"\n",
    "    print(f\"\\nRunning experiment: {experiment_name}\")\n",
    "\n",
    "    model = build_model(IMG_SHAPE)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    X, y = load_data(\n",
    "        [original_augmented_yes, original_augmented_no],\n",
    "        (IMG_WIDTH, IMG_HEIGHT),\n",
    "        grayscale=False,\n",
    "        contrast_enhancement=False,\n",
    "        anisotropic_diffusion=False,\n",
    "        smoothing=True,\n",
    "        bilateral_filtering=False,\n",
    "        kernel_size=kernel_size\n",
    "    )\n",
    "\n",
    "    plot_example_images(X, f\"{experiment_name}_{kernel_size}\")\n",
    "\n",
    "    # Split the data\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = split_data(X, y, test_size=0.3)\n",
    "\n",
    "    # Define file path for saving the model\n",
    "    filepath = os.path.join(model_dir, f\"{experiment_name}.keras\")\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=0, save_best_only=True, mode='max')\n",
    "\n",
    "    # Train the model\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        x=X_train, y=y_train,\n",
    "        batch_size=32,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=(X_val, y_val),\n",
    "        shuffle=True,\n",
    "        callbacks=[checkpoint],\n",
    "        verbose=1\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    # Get the best validation accuracy from this run\n",
    "    val_accuracy = max(history.history['val_accuracy'])\n",
    "    print(f\"{experiment_name} - Elapsed time: {hms_string(execution_time)} - Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    test_metrics = evaluate(model, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        'experiment_name': experiment_name,\n",
    "        'kernel_size': kernel_size,\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'test_metrics': test_metrics,\n",
    "        'execution_time': execution_time\n",
    "    })\n",
    "\n",
    "    # Update best parameters if this run is better\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        best_params = params\n",
    "\n",
    "# Prepare data for plotting\n",
    "kernel_sizes = [result['kernel_size'] for result in results]\n",
    "val_accuracies = [result['val_accuracy'] for result in results]\n",
    "\n",
    "# Create line plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(kernel_sizes, val_accuracies, marker='o', linestyle='-', color='b', label='Validation Accuracy')\n",
    "plt.title(\"Validation Accuracy vs. Kernel Size for Smoothing\")\n",
    "plt.xlabel(\"Kernel Size\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.xticks(kernel_sizes)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig(f\"images/{experiment_name}_grid-search.png\", dpi=300)\n",
    "\n",
    "# Print grid search results\n",
    "print(\"\\nGrid Search Results:\")\n",
    "for result in results:\n",
    "    print(f\"Experiment: {result['experiment_name']}, Val Accuracy: {result['val_accuracy']:.4f}, \"\n",
    "          f\"Time: {hms_string(result['execution_time'])}\")\n",
    "\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "print(f\"Best Validation Accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "# Print test metrics for the best parameters\n",
    "best_result = next(r for r in results if r['kernel_size'] == best_params['kernel_size'])\n",
    "print(f\"\\nTest Metrics for Best Parameters ({best_result['experiment_name']}):\")\n",
    "for metric_name, metric_value in best_result['test_metrics'].items():\n",
    "    print(f\"{metric_name}: {metric_value:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Bilateral Filtering"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "param_grid = {\n",
    "    'd': [5, 9],\n",
    "    'sigma_color': [10, 30, 50],\n",
    "    'sigma_space': [10, 30, 50]\n",
    "}\n",
    "\n",
    "best_val_accuracy = 0\n",
    "best_params = None\n",
    "results = []\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    d = params['d']\n",
    "    sigma_color = params['sigma_color']\n",
    "    sigma_space = params['sigma_space']\n",
    "\n",
    "    experiment_name = f\"bilateral_d{d}_sigmac{sigma_color}_sigmas{sigma_space}\"\n",
    "    print(f\"\\nRunning experiment: {experiment_name}\")\n",
    "\n",
    "    model = build_model(IMG_SHAPE)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    X, y = load_data(\n",
    "        [original_augmented_yes, original_augmented_no],\n",
    "        (IMG_WIDTH, IMG_HEIGHT),\n",
    "        grayscale=False,\n",
    "        contrast_enhancement=False,\n",
    "        anisotropic_diffusion=False,\n",
    "        smoothing=False,\n",
    "        bilateral_filtering=True,\n",
    "        d=d,\n",
    "        sigma_color=sigma_color,\n",
    "        sigma_space=sigma_space\n",
    "    )\n",
    "\n",
    "    plot_example_images(X, f\"{experiment_name}_d{d}_sigmac{sigma_color}_sigmas{sigma_space}\")\n",
    "\n",
    "    # Split the data\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = split_data(X, y, test_size=0.3)\n",
    "\n",
    "    # Define file path for saving the model\n",
    "    filepath = os.path.join(model_dir, f\"{experiment_name}.keras\")\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=0, save_best_only=True, mode='max')\n",
    "\n",
    "    # Train the model\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        x=X_train, y=y_train,\n",
    "        batch_size=32,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=(X_val, y_val),\n",
    "        shuffle=True,\n",
    "        callbacks=[checkpoint],\n",
    "        verbose=1\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    # Get the best validation accuracy from this run\n",
    "    val_accuracy = max(history.history['val_accuracy'])\n",
    "    print(f\"{experiment_name} - Elapsed time: {hms_string(execution_time)} - Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    test_metrics = evaluate(model, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        'experiment_name': experiment_name,\n",
    "        'd': d,\n",
    "        'sigma_color': sigma_color,\n",
    "        'sigma_space': sigma_space,\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'test_metrics': test_metrics,\n",
    "        'execution_time': execution_time\n",
    "    })\n",
    "\n",
    "    # Update best parameters if this run is better\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        best_params = params\n",
    "\n",
    "# Find the best 'd' value and create a heatmap for sigma_color vs. sigma_space\n",
    "best_d = best_params['d']\n",
    "sigma_colors = param_grid['sigma_color']\n",
    "sigma_spaces = param_grid['sigma_space']\n",
    "val_accuracies = np.zeros((len(sigma_colors), len(sigma_spaces)))\n",
    "\n",
    "for result in results:\n",
    "    if result['d'] == best_d:\n",
    "        i = sigma_colors.index(result['sigma_color'])\n",
    "        j = sigma_spaces.index(result['sigma_space'])\n",
    "        val_accuracies[i, j] = result['val_accuracy']\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(val_accuracies, annot=True, fmt=\".4f\", xticklabels=sigma_spaces, yticklabels=sigma_colors, cmap=\"YlGnBu\")\n",
    "plt.title(f\"Validation Accuracy for Bilateral Filtering (d={best_d})\")\n",
    "plt.xlabel(\"Sigma Space\")\n",
    "plt.ylabel(\"Sigma Color\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig(f\"images/{experiment_name}_grid-search.png\", dpi=300)\n",
    "\n",
    "# Print grid search results\n",
    "print(\"\\nGrid Search Results:\")\n",
    "for result in results:\n",
    "    print(f\"Experiment: {result['experiment_name']}, Val Accuracy: {result['val_accuracy']:.4f}, \"\n",
    "          f\"Time: {hms_string(result['execution_time'])}\")\n",
    "\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "print(f\"Best Validation Accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "# Print test metrics for the best parameters\n",
    "best_result = next(r for r in results if r['d'] == best_params['d'] and\n",
    "                   r['sigma_color'] == best_params['sigma_color'] and\n",
    "                   r['sigma_space'] == best_params['sigma_space'])\n",
    "print(f\"\\nTest Metrics for Best Parameters ({best_result['experiment_name']}):\")\n",
    "for metric_name, metric_value in best_result['test_metrics'].items():\n",
    "    print(f\"{metric_name}: {metric_value:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Anisotropic Diffusion Filtering"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "param_grid = {\n",
    "    'niter': [5, 10],\n",
    "    'kappa': [20, 50, 100],\n",
    "    'gamma': [0.05, 0.1, 0.15]\n",
    "}\n",
    "\n",
    "best_val_accuracy = 0\n",
    "best_params = None\n",
    "results = []\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    niter = params['niter']\n",
    "    kappa = params['kappa']\n",
    "    gamma = params['gamma']\n",
    "\n",
    "    experiment_name = f\"anisotropic_niter{niter}_kappa{kappa}_gamma{gamma}\"\n",
    "    print(f\"\\nRunning experiment: {experiment_name}\")\n",
    "\n",
    "    model = build_model(IMG_SHAPE)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    X, y = load_data(\n",
    "        [original_augmented_yes, original_augmented_no],\n",
    "        (IMG_WIDTH, IMG_HEIGHT),\n",
    "        grayscale=False,\n",
    "        contrast_enhancement=False,\n",
    "        anisotropic_diffusion=True,\n",
    "        smoothing=False,\n",
    "        bilateral_filtering=False,\n",
    "        aniso_niter=niter,\n",
    "        aniso_kappa=kappa,\n",
    "        aniso_gamma=gamma,\n",
    "        aniso_option=1\n",
    "    )\n",
    "\n",
    "    plot_example_images(X, f\"{experiment_name}_niter{niter}_kappa{kappa}_gamma{gamma}\")\n",
    "\n",
    "    # Split the data\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = split_data(X, y, test_size=0.3)\n",
    "\n",
    "    # Define file path for saving the model\n",
    "    filepath = os.path.join(model_dir, f\"{experiment_name}.keras\")\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=0, save_best_only=True, mode='max')\n",
    "\n",
    "    # Train the model\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        x=X_train, y=y_train,\n",
    "        batch_size=32,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=(X_val, y_val),\n",
    "        shuffle=True,\n",
    "        callbacks=[checkpoint],\n",
    "        verbose=1\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    # Get the best validation accuracy from this run\n",
    "    val_accuracy = max(history.history['val_accuracy'])\n",
    "    print(f\"{experiment_name} - Elapsed time: {hms_string(execution_time)} - Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    test_metrics = evaluate(model, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        'experiment_name': experiment_name,\n",
    "        'niter': niter,\n",
    "        'kappa': kappa,\n",
    "        'gamma': gamma,\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'test_metrics': test_metrics,\n",
    "        'execution_time': execution_time\n",
    "    })\n",
    "\n",
    "    # Update best parameters if this run is better\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        best_params = params\n",
    "\n",
    "# Find the best 'niter' value and create a heatmap for kappa vs. gamma\n",
    "best_niter = best_params['niter']\n",
    "kappas = param_grid['kappa']\n",
    "gammas = param_grid['gamma']\n",
    "val_accuracies = np.zeros((len(kappas), len(gammas)))\n",
    "\n",
    "for result in results:\n",
    "    if result['niter'] == best_niter:\n",
    "        i = kappas.index(result['kappa'])\n",
    "        j = gammas.index(result['gamma'])\n",
    "        val_accuracies[i, j] = result['val_accuracy']\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(val_accuracies, annot=True, fmt=\".4f\", xticklabels=gammas, yticklabels=kappas, cmap=\"YlGnBu\")\n",
    "plt.title(f\"Validation Accuracy for Anisotropic Diffusion (niter={best_niter}, option=1)\")\n",
    "plt.xlabel(\"Gamma\")\n",
    "plt.ylabel(\"Kappa\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig(f\"images/{experiment_name}_grid-search.png\", dpi=300)\n",
    "\n",
    "# Print grid search results\n",
    "print(\"\\nGrid Search Results:\")\n",
    "for result in results:\n",
    "    print(f\"Experiment: {result['experiment_name']}, Val Accuracy: {result['val_accuracy']:.4f}, \"\n",
    "          f\"Time: {hms_string(result['execution_time'])}\")\n",
    "\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "print(f\"Best Validation Accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "# Print test metrics for the best parameters\n",
    "best_result = next(r for r in results if r['niter'] == best_params['niter'] and\n",
    "                   r['kappa'] == best_params['kappa'] and\n",
    "                   r['gamma'] == best_params['gamma'])\n",
    "print(f\"\\nTest Metrics for Best Parameters ({best_result['experiment_name']}):\")\n",
    "for metric_name, metric_value in best_result['test_metrics'].items():\n",
    "    print(f\"{metric_name}: {metric_value:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Auditory Brain Implant Data Augmentation"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "implant_augmented_path = 'implant_augmented_data/'\n",
    "\n",
    "implant_augmented_yes = implant_augmented_path + 'yes'\n",
    "implant_augmented_no = implant_augmented_path + 'no'\n",
    "\n",
    "augment_data_implant(original_augmented_yes, implant_augmented_yes, percentage=0.025)\n",
    "augment_data_implant(original_augmented_no, implant_augmented_no, percentage=0.025)\n",
    "\n",
    "\n",
    "experiment_name = \"implant\"\n",
    "model = build_model(IMG_SHAPE)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "X, y = load_data(\n",
    "    [implant_augmented_yes, implant_augmented_no],\n",
    "    (IMG_WIDTH, IMG_HEIGHT),\n",
    "    grayscale=False,\n",
    "    contrast_enhancement=False,\n",
    "    anisotropic_diffusion=False,\n",
    "    smoothing=False,\n",
    "    bilateral_filtering=False\n",
    ")\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_data(X, y, test_size=0.3)\n",
    "\n",
    "# Static file path to ensure only the best model is saved\n",
    "filepath = os.path.join(model_dir, f\"{experiment_name}.keras\")\n",
    "\n",
    "# Save only the best model based on validation accuracy\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=0, save_best_only=True, mode='max')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model without checkpointing\n",
    "model.fit(x=X_train, y=y_train, batch_size=32, epochs=EPOCHS, validation_data=(X_val, y_val), shuffle=True, callbacks=[checkpoint], verbose=1)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = (end_time - start_time)\n",
    "print(f\"{experiment_name} - Elapsed time: {hms_string(execution_time)}\")\n",
    "\n",
    "evaluate(model, X_test, y_test, X_val, y_val)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
